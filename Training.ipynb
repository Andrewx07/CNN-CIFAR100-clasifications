{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ixO0ctC8lKj"
      },
      "source": [
        "##Training of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1_Z3VWdx8lKv"
      },
      "outputs": [],
      "source": [
        "# Libaries\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.optim as opt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn as nn\n",
        "from Custom_models import REDCN1, vgg16, ResNet9\n",
        "from Training_Func import training_cycle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHV73qfN8lKz"
      },
      "source": [
        "##Gpu activation (if is any available )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UoVCUjE_8lK0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lyog4UO8lK1"
      },
      "source": [
        "##Load of datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEkBsQVT8lK1",
        "outputId": "c4cb7ccf-93dd-4c40-a1fc-5df1ed7b5fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x79c101497a90>, 'test_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x79c101496dd0>, 'validation_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x79c101497280>, 'classes': ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'], 'batch_size': 10}\n"
          ]
        }
      ],
      "source": [
        "# data load\n",
        "PATH = \"./DATA.pth\"\n",
        "dataset = torch.load(PATH)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMaqJwUg8lK3"
      },
      "source": [
        "##Load of the network\n",
        "para este caso se utilizo una resnet 9 la cual posee capas paralelas."
![download.png](data:image/png;base64,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)
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRKAEHaQ8lK4",
        "outputId": "f173e6f4-ab73-4499-cb90-90b00d86e0e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet9(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res1): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res2): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (relu_linear): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model load\n",
        "Resnet = ResNet9()\n",
        "Resnet.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = opt.SGD(Resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "Resnet.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skeou0Bz8lK6"
      },
      "source": [
        "##training cycle\n",
        "para este caso se utiliza una funcion extener para poder tener acceso cuando sea necesario.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtatW01u8lK8",
        "outputId": "4470f6cd-c435-4aaf-8b6a-e1f3b7bb4f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Para la epoca 1 ] \n",
            "loss: 4.04764061126709\n",
            "\n",
            "val_loss: 3.5202944275140764\n",
            "\n",
            "Test Loss: 0.003245592493789832\n",
            "\n",
            "Test Accuracy : 16.35% where 1635 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 2 ] \n",
            "loss: 3.191585244679451\n",
            "\n",
            "val_loss: 2.7967385146021844\n",
            "\n",
            "Test Loss: 0.0018469183248782752\n",
            "\n",
            "Test Accuracy : 28.42% where 2842 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 3 ] \n",
            "loss: 2.6177000539898874\n",
            "\n",
            "val_loss: 2.2117672650814058\n",
            "\n",
            "Test Loss: 0.002059131535051028\n",
            "\n",
            "Test Accuracy : 38.24% where 3824 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 4 ] \n",
            "loss: 2.1593170057535174\n",
            "\n",
            "val_loss: 1.886040624976158\n",
            "\n",
            "Test Loss: 0.00330417851107101\n",
            "\n",
            "Test Accuracy : 42.41% where 4241 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 5 ] \n",
            "loss: 1.8101388414502144\n",
            "\n",
            "val_loss: 1.4655912781655789\n",
            "\n",
            "Test Loss: 0.0012772283735937393\n",
            "\n",
            "Test Accuracy : 47.37% where 4737 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 6 ] \n",
            "loss: 1.5124592335939406\n",
            "\n",
            "val_loss: 1.126591967061162\n",
            "\n",
            "Test Loss: 0.002611616409269213\n",
            "\n",
            "Test Accuracy : 51.68% where 5168 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 7 ] \n",
            "loss: 1.2542742523282766\n",
            "\n",
            "val_loss: 0.960802865743637\n",
            "\n",
            "Test Loss: 0.0030345771604884113\n",
            "\n",
            "Test Accuracy : 52.0% where 5200 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 8 ] \n",
            "loss: 1.0124690453596412\n",
            "\n",
            "val_loss: 0.7562664635702968\n",
            "\n",
            "Test Loss: 0.0013167650808056043\n",
            "\n",
            "Test Accuracy : 52.02% where 5202 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 9 ] \n",
            "loss: 0.7876858870934695\n",
            "\n",
            "val_loss: 0.5012584922462702\n",
            "\n",
            "Test Loss: 0.002426926741450287\n",
            "\n",
            "Test Accuracy : 52.76% where 5276 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 10 ] \n",
            "loss: 0.5898679638613016\n",
            "\n",
            "val_loss: 0.3870402131443843\n",
            "\n",
            "Test Loss: 0.0015550821805472236\n",
            "\n",
            "Test Accuracy : 52.48% where 5248 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 11 ] \n",
            "loss: 0.43774992740303276\n",
            "\n",
            "val_loss: 0.2805233543985523\n",
            "\n",
            "Test Loss: 0.0019126931299648859\n",
            "\n",
            "Test Accuracy : 52.16% where 5216 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 12 ] \n",
            "loss: 0.3300263135341462\n",
            "\n",
            "val_loss: 0.19754473841679282\n",
            "\n",
            "Test Loss: 0.003765932082932327\n",
            "\n",
            "Test Accuracy : 52.49% where 5249 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 13 ] \n",
            "loss: 0.27090836676287\n",
            "\n",
            "val_loss: 0.2440148916647304\n",
            "\n",
            "Test Loss: 0.002197721756869277\n",
            "\n",
            "Test Accuracy : 51.03% where 5103 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 14 ] \n",
            "loss: 0.21000558632980101\n",
            "\n",
            "val_loss: 0.1446992907065287\n",
            "\n",
            "Test Loss: 0.0007877364809528491\n",
            "\n",
            "Test Accuracy : 51.93% where 5193 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 15 ] \n",
            "loss: 0.17713608674751885\n",
            "\n",
            "val_loss: 0.1776300092844176\n",
            "\n",
            "Test Loss: 0.0030662416537086965\n",
            "\n",
            "Test Accuracy : 51.34% where 5134 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 16 ] \n",
            "loss: 0.13796829742825795\n",
            "\n",
            "val_loss: 0.11098833732945787\n",
            "\n",
            "Test Loss: 0.00425099930081924\n",
            "\n",
            "Test Accuracy : 52.44% where 5244 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 17 ] \n",
            "loss: 0.11448884040940248\n",
            "\n",
            "val_loss: 0.10959728216884833\n",
            "\n",
            "Test Loss: 0.00398779940921701\n",
            "\n",
            "Test Accuracy : 53.02% where 5302 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 18 ] \n",
            "loss: 0.09511554939194321\n",
            "\n",
            "val_loss: 0.08665559988699534\n",
            "\n",
            "Test Loss: 0.002199996499644799\n",
            "\n",
            "Test Accuracy : 53.03% where 5303 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 19 ] \n",
            "loss: 0.09102188689580121\n",
            "\n",
            "val_loss: 0.08670064733781692\n",
            "\n",
            "Test Loss: 0.004416707041181497\n",
            "\n",
            "Test Accuracy : 52.95% where 5295 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 20 ] \n",
            "loss: 0.07713938885467506\n",
            "\n",
            "val_loss: 0.06205613348636507\n",
            "\n",
            "Test Loss: 0.0006395121617820721\n",
            "\n",
            "Test Accuracy : 53.57% where 5357 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 21 ] \n",
            "loss: 0.06395271090030347\n",
            "\n",
            "val_loss: 0.029220303313046314\n",
            "\n",
            "Test Loss: 0.0031723463837820113\n",
            "\n",
            "Test Accuracy : 55.02% where 5502 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 22 ] \n",
            "loss: 0.06385101104905384\n",
            "\n",
            "val_loss: 0.061367877615222825\n",
            "\n",
            "Test Loss: 0.005072199545748307\n",
            "\n",
            "Test Accuracy : 53.42% where 5342 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 23 ] \n",
            "loss: 0.05167654819481169\n",
            "\n",
            "val_loss: 0.04476654428249549\n",
            "\n",
            "Test Loss: 0.002414692042573118\n",
            "\n",
            "Test Accuracy : 53.37% where 5337 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 24 ] \n",
            "loss: 0.03899082498185289\n",
            "\n",
            "val_loss: 0.03578179293327775\n",
            "\n",
            "Test Loss: 0.0023791466314170215\n",
            "\n",
            "Test Accuracy : 53.75% where 5375 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 25 ] \n",
            "loss: 0.04034727905938572\n",
            "\n",
            "val_loss: 0.03599140355030977\n",
            "\n",
            "Test Loss: 0.006650758002935458\n",
            "\n",
            "Test Accuracy : 53.98% where 5398 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 26 ] \n",
            "loss: 0.03739652841058307\n",
            "\n",
            "val_loss: 0.0200940844767847\n",
            "\n",
            "Test Loss: 0.005647580288487091\n",
            "\n",
            "Test Accuracy : 54.17% where 5417 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 27 ] \n",
            "loss: 0.026148100030677687\n",
            "\n",
            "val_loss: 0.028871582938880577\n",
            "\n",
            "Test Loss: 0.004589699207728066\n",
            "\n",
            "Test Accuracy : 54.08% where 5408 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 28 ] \n",
            "loss: 0.0221031807848756\n",
            "\n",
            "val_loss: 0.012003886398432315\n",
            "\n",
            "Test Loss: 0.0028930214487164255\n",
            "\n",
            "Test Accuracy : 54.9% where 5490 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 29 ] \n",
            "loss: 0.01564559246074866\n",
            "\n",
            "val_loss: 0.012504767585948684\n",
            "\n",
            "Test Loss: 0.0030532084401899756\n",
            "\n",
            "Test Accuracy : 54.86% where 5486 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 30 ] \n",
            "loss: 0.01358966256924563\n",
            "\n",
            "val_loss: 0.008385640700622275\n",
            "\n",
            "Test Loss: 0.0025944826968495667\n",
            "\n",
            "Test Accuracy : 55.48% where 5548 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 31 ] \n",
            "loss: 0.007937879730388522\n",
            "\n",
            "val_loss: 0.011505310735461328\n",
            "\n",
            "Test Loss: 0.007752297305900385\n",
            "\n",
            "Test Accuracy : 55.6% where 5560 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 32 ] \n",
            "loss: 0.006957217740936571\n",
            "\n",
            "val_loss: 0.003450299432055431\n",
            "\n",
            "Test Loss: 0.0030268059863414734\n",
            "\n",
            "Test Accuracy : 56.28% where 5628 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 33 ] \n",
            "loss: 0.0055284471965895135\n",
            "\n",
            "val_loss: 0.0019271813453596565\n",
            "\n",
            "Test Loss: 0.00164296107666353\n",
            "\n",
            "Test Accuracy : 56.47% where 5647 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 34 ] \n",
            "loss: 0.004803748022488059\n",
            "\n",
            "val_loss: 0.0032916513238374135\n",
            "\n",
            "Test Loss: 7.629624958488857e-05\n",
            "\n",
            "Test Accuracy : 56.15% where 5615 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 35 ] \n",
            "loss: 0.0037257932628284494\n",
            "\n",
            "val_loss: 0.003287357734160196\n",
            "\n",
            "Test Loss: 0.003072419045862701\n",
            "\n",
            "Test Accuracy : 56.37% where 5637 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 36 ] \n",
            "loss: 0.004396425911886604\n",
            "\n",
            "val_loss: 0.0019521551442336432\n",
            "\n",
            "Test Loss: 0.0021734161893205645\n",
            "\n",
            "Test Accuracy : 56.65% where 5665 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 37 ] \n",
            "loss: 0.002703481004631874\n",
            "\n",
            "val_loss: 0.0021748243252809516\n",
            "\n",
            "Test Loss: 0.004394294824454609\n",
            "\n",
            "Test Accuracy : 56.88% where 5688 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 38 ] \n",
            "loss: 0.0030044422733247985\n",
            "\n",
            "val_loss: 0.002210284004626146\n",
            "\n",
            "Test Loss: 0.0038490901528383673\n",
            "\n",
            "Test Accuracy : 56.32% where 5632 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 39 ] \n",
            "loss: 0.0027924612407051997\n",
            "\n",
            "val_loss: 0.00239316242896507\n",
            "\n",
            "Test Loss: 0.005851659619126668\n",
            "\n",
            "Test Accuracy : 56.93% where 5693 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 40 ] \n",
            "loss: 0.0030369875775825223\n",
            "\n",
            "val_loss: 0.0015506543506878642\n",
            "\n",
            "Test Loss: 0.0028682175232261358\n",
            "\n",
            "Test Accuracy : 56.99% where 5699 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 41 ] \n",
            "loss: 0.002638212168609448\n",
            "\n",
            "val_loss: 0.0007890414656746998\n",
            "\n",
            "Test Loss: 0.000830734944894889\n",
            "\n",
            "Test Accuracy : 56.93% where 5693 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 42 ] \n",
            "loss: 0.0021578913988825606\n",
            "\n",
            "val_loss: 0.00022774316641391577\n",
            "\n",
            "Test Loss: 0.0018998286901513073\n",
            "\n",
            "Test Accuracy : 56.94% where 5694 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 43 ] \n",
            "loss: 0.0022475857490897623\n",
            "\n",
            "val_loss: 0.0008923254434998853\n",
            "\n",
            "Test Loss: 0.0030148863158831504\n",
            "\n",
            "Test Accuracy : 57.03% where 5703 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 44 ] \n",
            "loss: 0.0021026561856000397\n",
            "\n",
            "val_loss: 0.0019451882763355571\n",
            "\n",
            "Test Loss: 0.005514228886843032\n",
            "\n",
            "Test Accuracy : 57.02% where 5702 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 45 ] \n",
            "loss: 0.0017440317202323796\n",
            "\n",
            "val_loss: 0.00018520069552505446\n",
            "\n",
            "Test Loss: 0.0015079032746317474\n",
            "\n",
            "Test Accuracy : 57.31% where 5731 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 46 ] \n",
            "loss: 0.002101778392855003\n",
            "\n",
            "val_loss: 0.0008959749264959101\n",
            "\n",
            "Test Loss: 0.005389539642556485\n",
            "\n",
            "Test Accuracy : 57.26% where 5726 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 47 ] \n",
            "loss: 0.001961129630459641\n",
            "\n",
            "val_loss: 0.0001841296785582358\n",
            "\n",
            "Test Loss: 0.00429155339251889\n",
            "\n",
            "Test Accuracy : 57.17% where 5717 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 48 ] \n",
            "loss: 0.0014996717651442112\n",
            "\n",
            "val_loss: 0.002639186362820055\n",
            "\n",
            "Test Loss: 0.003064274423122498\n",
            "\n",
            "Test Accuracy : 56.98% where 5698 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 49 ] \n",
            "loss: 0.001729897446910647\n",
            "\n",
            "val_loss: 0.0002902575154883493\n",
            "\n",
            "Test Loss: 0.003346427899211779\n",
            "\n",
            "Test Accuracy : 56.94% where 5694 of 10000 were predicted correctly\n",
            "\n",
            "[Para la epoca 50 ] \n",
            "loss: 0.0015961497141544897\n",
            "\n",
            "val_loss: 0.0016053704783839749\n",
            "\n",
            "Test Loss: 0.0023091547344675275\n",
            "\n",
            "Test Accuracy : 57.26% where 5726 of 10000 were predicted correctly\n"
          ]
        }
      ],
      "source": [
        "# training cycle\n",
        "training_time = 50\n",
        "graphic1 = []\n",
        "graphic2 = []\n",
        "running_epoch = []\n",
        "acc = []\n",
        "class_total = []\n",
        "class_correct = []\n",
        "\n",
        "(\n",
        "    graphic1,\n",
        "    graphic2,\n",
        "    running_epoch,\n",
        "    acc,\n",
        "    class_total,\n",
        "    class_correct,\n",
        "    test_loss,\n",
        ") = training_cycle(Resnet, training_time, optimizer, criterion, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEIIMhHt8lK9"
      },
      "source": [
        "##Saving the trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mtwD7_2j8lK-"
      },
      "outputs": [],
      "source": [
        "# Saved Model\n",
        "PATH = \"./trained_model/Resnet9_trained.pth\"\n",
        "torch.save(\n",
        "    {\n",
        "        \"epoch\": running_epoch,\n",
        "        \"model_state_dict\": Resnet.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"loss_epoch\": graphic1,\n",
        "        \"loss_epoch_validation\": graphic2,\n",
        "        \"acc\": acc,\n",
        "        \"class_total\": class_total,\n",
        "        \"class_correct\": class_correct,\n",
        "        \"test_loss\": test_loss,\n",
        "    },\n",
        "    PATH,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
